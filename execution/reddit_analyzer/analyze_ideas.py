import argparse
import json
import os
import sqlite3
from datetime import datetime, timedelta

import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables from the root .env
dotenv_path = os.path.join(
    os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"
)
load_dotenv(dotenv_path)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("Error: GOOGLE_API_KEY not found in .env")
    exit(1)

GOOGLE_MODEL = os.getenv("GOOGLE_MODEL", "gemini-3-flash-preview")

genai.configure(api_key=GOOGLE_API_KEY)

# Config
CONFIG_PATH = os.path.join(os.path.dirname(__file__), "config.json")
with open(CONFIG_PATH, "r") as f:
    config = json.load(f)

DB_NAME = os.path.join(os.path.dirname(__file__), config["db_name"])

import time

from google.api_core import exceptions

# Import Reddit image generation components
try:
    from .tools.reddit_image_generator import generate_reddit_visual
    from .utils.file_manager import RedditImageFileManager
except ImportError:
    generate_reddit_visual = None
    RedditImageFileManager = None


class RedditAnalyzerWithImages:
    """Analyseur Reddit avec g√©n√©ration d'images int√©gr√©e."""

    def __init__(self):
        self.file_manager = RedditImageFileManager() if RedditImageFileManager else None
        self.image_config = self._load_image_config()

    def _load_image_config(self) -> dict:
        """Charge la configuration de g√©n√©ration d'images."""
        try:
            config_path = os.path.join(os.path.dirname(__file__), "config.json")
            with open(config_path, "r") as f:
                config = json.load(f)
                return config.get("reddit_image_settings", {})
        except:
            return {}

    def analyze_and_generate_images(self, category: str) -> dict:
        """Analyse les id√©es et g√©n√®re des images associ√©es."""

        # Analyse existante
        posts = get_recent_posts(hours=24, category=category)
        if not posts:
            return {
                "ideas": [],
                "error": f"Aucun post trouv√© pour la cat√©gorie {category}",
            }

        # Analyse des posts
        analysis_text = analyze_posts(posts, category_name=category)

        # Parser l'analyse pour extraire les id√©es
        ideas = self._parse_analysis_for_images(analysis_text)

        # V√©rifier si la g√©n√©ration d'images est activ√©e
        if not self.image_config.get("enabled", True) or not generate_reddit_visual:
            return {"ideas": ideas, "analysis": analysis_text}

        # G√©n√©rer des images pour les id√©es pertinentes
        for idea in ideas:
            if self._should_generate_image(idea):
                prompt = self._create_image_prompt(idea, category)
                try:
                    image_path = generate_reddit_visual(prompt)
                    idea["generated_image"] = image_path
                except Exception as e:
                    print(
                        f"Erreur lors de la g√©n√©ration d'image pour l'id√©e '{idea.get('title', 'Unknown')}': {e}"
                    )

        return {"ideas": ideas, "analysis": analysis_text}

    def _parse_analysis_for_images(self, analysis_text: str) -> list:
        """Extrait les id√©es de l'analyse textuelle."""
        ideas = []

        # Simple parsing - chercher les sections d'id√©es
        lines = analysis_text.split("\n")
        current_idea = {}

        for line in lines:
            line = line.strip()

            # D√©tecter le d√©but d'une nouvelle id√©e
            if line.startswith("### ") and not line.startswith("### Top"):
                if current_idea:
                    ideas.append(current_idea)

                title = line.replace("### ", "").strip()
                current_idea = {
                    "title": title,
                    "problem": "",
                    "solution": "",
                    "needs_visualization": True,
                }

            # Extraire le probl√®me
            elif line.startswith("**üßê Le Probl√®me / Insight :**"):
                problem_lines = []
                i = lines.index(line) + 1
                while i < len(lines) and not lines[i].strip().startswith("**üí°"):
                    problem_lines.append(lines[i].strip())
                    i += 1

                current_idea["problem"] = " ".join(problem_lines).strip()

            # Extraire la solution
            elif line.startswith("**üí° Solution / Produit Propos√© :**"):
                solution_lines = []
                i = lines.index(line) + 1
                while i < len(lines) and (
                    not lines[i].strip() or not lines[i].strip().startswith("---")
                ):
                    if lines[i].strip():
                        solution_lines.append(lines[i].strip())
                    i += 1

                current_idea["solution"] = " ".join(solution_lines).strip()

        if current_idea:
            ideas.append(current_idea)

        return ideas

    def _should_generate_image(self, idea: dict) -> bool:
        """D√©termine si une id√©e m√©rite une image g√©n√©r√©e."""
        # Crit√®res bas√©s sur le contenu
        title = idea.get("title", "").lower()
        problem = idea.get("problem", "").lower()
        solution = idea.get("solution", "").lower()

        # G√©n√©rer une image si l'id√©e semble pertinente
        has_business_keywords = any(
            keyword in title or keyword in problem or keyword in solution
            for keyword in [
                "app",
                "software",
                "tool",
                "platform",
                "service",
                "saas",
                "business",
            ]
        )

        return has_business_keywords and (len(problem) > 10 or len(solution) > 10)

    def _create_image_prompt(self, idea: dict, category: str) -> str:
        """Cr√©e un prompt d'image bas√© sur l'id√©e Reddit."""
        title = idea.get("title", "")
        problem = idea.get("problem", "")
        solution = idea.get("solution", "")

        prompt_template = """
        Professional visualization for Reddit post: "{title}"
        
        Category: {category}
        Problem: {problem}
        Solution: {solution}
        
        Create a modern, clean visual representation that captures the essence of this business/concept.
        Use professional business imagery with colors appropriate for {category}.
        Include visual metaphors that represent the core idea.
        
        Style: Modern business infographic with clean lines
        Colors: Professional palette matching {category} theme
        Composition: Balanced and visually appealing
        """

        return prompt_template.format(
            title=title,
            category=category,
            problem=problem[:100],
            solution=solution[:100],
        ).strip()


def get_recent_posts(hours=24, limit=20, category=None):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()

    # Calculate cutoff time
    cutoff = (datetime.now() - timedelta(hours=hours)).isoformat()

    # Define subreddits filter
    target_subreddits = []
    if category:
        if "subreddits" in config:
            target_subreddits = [
                s["name"]
                for s in config["subreddits"]
                if isinstance(s, dict) and s.get("category") == category
            ]

        if not target_subreddits:
            print(f"Warning: No subreddits found for category '{category}'.")
            return []

    query = "SELECT title, summary, subreddit, link FROM posts WHERE fetched_at > ?"
    params = [cutoff]

    if target_subreddits:
        placeholders = ",".join("?" for _ in target_subreddits)
        query += f" AND subreddit IN ({placeholders})"
        params.extend(target_subreddits)

    query += " ORDER BY fetched_at DESC LIMIT ?"
    params.append(limit)

    c.execute(query, tuple(params))
    posts = c.fetchall()
    conn.close()
    return posts


def analyze_posts(posts, category_name="G√©n√©ral"):
    if not posts:
        return f"Aucun post r√©cent trouv√© pour la cat√©gorie {category_name}."

    # Construct Prompt
    posts_text = ""
    for p in posts:
        title, summary, sub, link = p
        # Limit summary length further to save tokens
        posts_text += (
            f"- [{sub}] {title}\n  Summary: {summary[:150]}...\n  Link: {link}\n\n"
        )

    prompt = f"""
    Tu es un analyste commercial expert. Analyse les publications Reddit suivantes provenant de la cat√©gorie '{category_name}'.
    Identifie 5 id√©es de business prometteuses, tendances ou probl√®mes ("pain points") que des entrepreneurs pourraient r√©soudre.

    Formate ta r√©ponse sous forme de rapport Markdown en FRAN√áAIS.
    IMPORTANT : N'utilise PAS de tableau pour les id√©es. Utilise le format suivant pour une lisibilit√© maximale :

    # Rapport d'Id√©es Business : {category_name}

    ## üìä R√©sum√© Ex√©cutif
    Un aper√ßu de 2 phrases sur le sentiment actuel dans cette niche.

    ## üöÄ Top 5 Opportunit√©s

    ### 1. [Nom de l'Id√©e/Tendance]
    **üßê Le Probl√®me / Insight :**
    [Description du probl√®me. Cite le contexte sp√©cifique du post reddit ici]

    **üí° Solution / Produit Propos√© :**
    [Description concr√®te de la solution]

    ---
    (R√©p√®te pour les id√©es 2 √† 5)

    Voici les donn√©es √† analyser :
    {posts_text}
    """

    model = genai.GenerativeModel(GOOGLE_MODEL)

    # Simple retry logic
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return response.text
        except exceptions.ResourceExhausted as e:
            print(
                f"Quota exceeded (attempt {attempt + 1}/{max_retries}). Retrying in 20 seconds..."
            )
            time.sleep(20)
        except Exception as e:
            print(f"An error occurred: {e}")
            return f"Analysis failed due to error: {e}"

    return "Analysis failed after retries due to quota limits."


def main():
    parser = argparse.ArgumentParser(
        description="Analyze Reddit posts for business ideas."
    )
    parser.add_argument(
        "--category", type=str, help="Category name from config.json to analyze"
    )
    args = parser.parse_args()

    print(
        f"Fetching recent posts for category: {args.category if args.category else 'ALL'}..."
    )
    posts = get_recent_posts(hours=24, category=args.category)
    print(f"Found {len(posts)} posts. Analyzing with Gemini...")

    cat_display_name = args.category if args.category else "Business G√©n√©ral"
    analysis = analyze_posts(posts, category_name=cat_display_name)

    print("\n--- ANALYSIS REPORT ---\n")
    print(analysis)

    # Save to a temporary file specific to the category
    filename = (
        f"latest_analysis_{args.category}.md" if args.category else "latest_analysis.md"
    )
    output_path = os.path.join(os.path.dirname(__file__), filename)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(analysis)
    print(f"\nAnalysis saved to {output_path}")


if __name__ == "__main__":
    main()
